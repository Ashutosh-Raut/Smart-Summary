<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="style.css">
    <!-- down chevron -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">
    <!-- right chevron -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@48,400,0,0">
    <!-- sell tag -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">
    <!-- location  -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">
    <!-- email -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">
    <!-- search -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">
    <!-- translate -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@48,400,0,0">

    <!-- calendar -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">
    <!-- play -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">
    <!-- note -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">
    <!-- air -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">
    <!-- plus -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">
    <!-- 3 -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">
    <!-- code -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">

    <title>Smart Summary</title>
</head>

<body>

    <nav class="navbar">

        <div class="top-container">

            <ul class="dropdowns">

                <li class="dropdown">
                    <a href="#" class="dropdown-text">University<span class="material-symbols-outlined">expand_more</span></a>
                </li>

                <li class="dropdown">
                    <a href="#" class="dropdown-text">Branch<span class="material-symbols-outlined">expand_more</span></a>
                </li>

            </ul>

            <div id="logo"><a href="main.html"><img src="logo.png" height="30px" width="160px"></a></div>

            <ul class="interactions">
                
                <li class="sign-in"><a href="#" style="padding: 0 20px 0 20px;">Sign In</a></li>
            </ul>
        </div>
    </nav>
    <div class="topic-container">
        <ul class="topics">
            <li><a href="dsa.html">DSA</a></li>
            <li><a href="ai.html"><div class="footer-link-heading">Artificial Intelligence</div></a></li>
            <li><a href="ml.html">Machine Learning</a></li>
            <li><a href="cc.html">Cloud Computing</a></li>
            <li><a href="se.html">Software Engineering</a></li>
            <li><a href="cn.html">Computer Network</a></li>
            <li><a href="os.html">Operating System</a></li>
            <li><a href="dbs.html">DBMS</a></li>
            <li><a href="oops.html">OOPs</a></li>
            <li><a href="daa.html">DAA</a></li>
        </ul>
    </div>

    <main>

        <div class="article-container">

            <div class="sidebar">
                <ul class="sidebar-menu">
                    <li><a href="#unit1">UNIT 1: Introduction</a></li>
                    <li><a href="#unit2">UNIT 2: Problem-solving</a></li>
                    <li><a href="#unit3">UNIT 3: Knowledge & Reasoning</a></li>
                    <li><a href="#unit4">UNIT 4: Probabilistic Reasoning</a></li>
                    <li><a href="#unit5">UNIT 5: Natural Language processing</a></li>
                </ul>
            </div>

            <div class="main-content">

                <div id="unit1" class="formatted-text">
                    <!-- Unit 1 text -->
                    <h2>UNIT 1: Introduction</h2>
                    <br>
                    <section>
                        <h3>1.1 What is Artificial Intelligence?</h3>
                        <br>
                        <p>Artificial Intelligence (AI) is a rapidly evolving field in computer science, aiming to create intelligent machines capable of human-like behavior and decision-making. It encompasses a wide range of applications, from self-driving cars to playing games like chess and composing music. AI seeks to replicate human cognitive abilities such as learning, reasoning, and problem-solving. Unlike traditional programming, AI allows machines to operate autonomously, learning from their environment without explicit programming for every task. The term "Artificial Intelligence" combines "artificial," meaning man-made, with "intelligence," referring to thinking power. AI systems are designed to exhibit traits like adaptability, learning, and autonomous decision-making. Despite its contemporary popularity, the concept of AI has historical roots, with references to mechanical beings in ancient myths.</p><br>
                        <p>Different perspectives on defining AI exist, considering factors like thought processes, behavior, and measures of success such as fidelity to human performance or rationality. Understanding AI's fundamental concepts, applications, and historical context is crucial for engineering exams. Mastery of AI concepts involves grasping the creation of intelligent machines, their learning capabilities, and the diverse applications across various domains. Proficiency in articulating key definitions and perspectives on AI enhances one's ability to address exam questions related to artificial intelligence and its implications in engineering.</p><br>
                    </section>
                    
                    <section>
                        <h3>1.2 Foundations of AI:</h3>
                        <br>
                        <p>Artificial Intelligence (AI) draws from various disciplines to form its foundation. These disciplines include mathematics, biology, psychology, sociology, computer science, and neuroscience. Understanding intelligence involves recognizing components like reasoning, learning, problem-solving, perception, and language understanding.</p><br>
                        <p>Philosophical inquiries into AI's foundation date back to ancient times, with Aristotle's exploration of rationality and reasoning. Descartes introduced dualism, suggesting the mind operates beyond physical laws, while materialism posits the brain's operation as the basis of the mind. Empiricism addresses knowledge acquisition from sensory experiences, while logical positivism combines rationalism and empiricism.</p><br>
                        <p>Mathematics plays a crucial role in AI, particularly in logic, computation, and probability. Logical formalization started with Boole's propositional logic and Frege's extension to first-order logic. Godel's incompleteness theorem highlights the limitations of logical deduction, motivating Turing's exploration of computability and the Church-Turing thesis.</p><br>
                        <p>Economics contributes decision theory, exploring rational decision-making under uncertainty. Game theory analyzes strategic interactions, while operations research deals with sequential decision problems. Herbert Simon's concept of satisficing provides insights into human decision-making.</p><br>
                        <p>Neuroscience offers insights into brain function, particularly through studies of neurons and brain localization. Broca's work on speech production localization and Golgi's staining technique for observing neurons were pivotal. Mathematical models applied by Rashevsky contributed to understanding the nervous system.</p><br>
                        <p>Computer Engineering: The evolution of computing hardware, from early machines like the Colossus and ENIAC to modern CPUs, has been pivotal for AI development. Figures like Alan Turing contributed significantly to early AI efforts.</p><br>
                        <p>Control Theory and Cybernetics: Led by Norbert Wiener, Control Theory explored self-regulating feedback systems, providing insights into AI's adaptive behavior. It emphasized minimizing "error" between current and goal states.</p><br>
                        <p>Linguistics Intersection: Linguistics intersected with AI, notably through Noam Chomsky's theories, leading to computational linguistics and natural language processing. Understanding language complexity became crucial for AI advancement.</p><br>
                    </section>
                    
                    <section>
                        <h3>1.3 History of AI:</h3>
                        <br>
                        <p>Artificial Intelligence (AI) has a rich history dating back to the mid-20th century. Its origins trace back to Warren McCulloch and Walter Pitts' work on artificial neurons in 1943, followed by Donald Hebb's development of Hebbian learning in 1949. In 1950, Alan Turing proposed the Turing test to assess machines' intelligent behavior, marking a significant milestone. The term "Artificial Intelligence" was coined in 1956 by John McCarthy at the Dartmouth Conference, establishing AI as an academic field.</p><br>
                        <p>The early years saw the creation of the first AI program, Logic Theorist, by Allen Newell and Herbert A. Simon in 1955, and the development of high-level computer languages like FORTRAN and LISP. Subsequent decades witnessed milestones like Joseph Weizenbaum's creation of the ELIZA chatbot in 1966 and the construction of the first intelligent humanoid robot, WABOT-1, in 1972.</p><br>
                        <p>However, AI research faced challenges during the AI winters of 1974-1980 and 1987-1993, characterized by funding shortages and decreased public interest. Despite setbacks, AI experienced resurgence with the advent of Expert Systems in the 1980s, which emulated human decision-making. The emergence of intelligent agents in the 1990s marked another milestone, highlighted by IBM Deep Blue defeating chess champion Gary Kasparov in 1997.</p><br>
                        <p>Recent years have seen remarkable advancements, including IBM's Watson winning Jeopardy in 2011, Google's launch of Google Now in 2012, and the development of chatbots like Eugene Goostman, which won the Turing test in 2014. Notable achievements include IBM's Project Debater engaging in complex debates and Google's Duplex AI making natural language phone calls, showcasing AI's capabilities.</p><br>
                        <p>Today, AI stands at the forefront of technological innovation, with deep learning, big data, and artificial general intelligence driving advancements. Major companies like Google, Facebook, IBM, and Amazon are heavily invested in AI research, promising an inspiring future of high intelligence and transformative technologies.</p><br>
                    </section>

                    <section>
                        <h3>1.4 State of Art of AI:</h3>
                        <br>
                        <p>Artificial Intelligence (AI) has made significant strides in various domains, showcasing its capabilities across different applications. In robotics, companies like Tesla have developed autonomous vehicles, while iRobot Corporation's Roomba serves as a popular robotic vacuum cleaner for home use. AI-powered speech recognition systems like Google Assistant and Siri have revolutionized customer interactions, enabling automated conversations for tasks such as flight booking.</p><br>
                        <p>Autonomous planning and scheduling have seen breakthroughs with NASA's Remote Agent program, which controlled spacecraft operations autonomously, and subsequent programs like MAPGEN and MEXAR2 managing missions for Mars exploration. Game-playing AI reached new heights when IBM's Deep Blue defeated world chess champion Garry Kasparov, demonstrating sophisticated decision-making abilities.</p><br>
                        <p>Spam fighting algorithms, utilized by platforms like Truecaller and Spam Detector, employ learning algorithms to classify messages efficiently, alleviating the burden of spam for users. Logistics planning has been revolutionized by AI, exemplified by DARPA's DART system, which significantly streamlined transportation logistics during the Persian Gulf crisis.</p><br>
                        <p>Machine translation has seen advancements with programs like Google Translate, leveraging statistical models to translate between languages accurately. These examples illustrate the tangible impact of AI in solving real-world problems, emphasizing the role of science, engineering, and mathematics in AI development.</p><br>
                        <p>From robotic vehicles navigating complex terrains to speech recognition systems assisting travelers, AI continues to push boundaries, offering solutions that were once deemed science fiction. As AI technologies mature, they promise to further transform industries, driving innovation and shaping the future of engineering and technology.</p><br>
                    </section>
                    
                    <section>
                        <h3>1.5 Intelligent Agents: Agents and Environment:</h3>
                        <br>
                        <p>Agents in Artificial Intelligence (AI) play a pivotal role in perceiving their environment and taking actions based on sensory inputs through actuators. These agents can be categorized into five classes, each exhibiting varying degrees of perceived intelligence and capability for improving performance over time.</p><br>
                        <p>Simple Reflex Agent: Simple reflex agents make decisions based solely on current percepts, disregarding percept history. They operate on condition-action rules, suitable for fully observable environments. However, their design approach poses limitations due to their limited intelligence and lack of adaptability to environmental changes.</p><br>
                        <p>Model-based Reflex Agent: Model-based agents operate in partially observable environments, leveraging a model of the world and internal state representation based on percept history. These agents track situations and update their state based on how the world evolves and how their actions affect it.</p><br>
                        <p>Goal-based Agents: In situations where knowledge of the current state is insufficient, goal-based agents come into play. These agents possess goal information, enabling them to choose actions aimed at achieving predefined objectives. They employ searching and planning to consider various action sequences, making them proactive in achieving goals.</p><br>
                        <p>Utility-based Agents: Utility-based agents, akin to goal-based agents, incorporate utility measurement to evaluate the effectiveness of actions in achieving goals. They prioritize actions based on utility function mappings, particularly useful when multiple alternatives exist, ensuring optimal decision-making.</p><br>
                        <p>Learning Agents: Learning agents possess the capability to learn from past experiences, adapting and improving their performance over time. These agents comprise learning elements responsible for improvement, critics providing feedback, performance elements selecting actions, and problem generators suggesting new actions for informative experiences.</p><br>
                        <p>Intelligent agents encompass a broad spectrum, including human agents, robotic agents, and software agents, all characterized by their ability to perceive and act upon their environment. Rational agents, adhering to predefined rules, aim to maximize performance by making rational decisions based on preferences and uncertainty modeling.</p><br>
                        <p>The agent function defines an agent's behavior, mapping percept sequences to actions, while the agent program implements this function within a physical system. Understanding agents facilitates system analysis and design, emphasizing AI's role in decision-making within complex environments.</p><br>
                    </section>                    
                    
                    <section>
                        <h3>1.6 Good Behaviour : The concept of Rationality :</h3><br>
                        <p>The rationality of an agent is measured by its performance measure. Rationality can be judged on the basis of following points: Performance measure which defines the success criterion. Agent prior knowledge of its environment. Best possible actions that an agent can perform. The sequence of percepts. An environment is everything in the world which surrounds the agent, but it is not a part of an agent itself. An environment can be described as a situation in which an agent is present. The environment is where agent lives, operate and provide the agent with something to sense and act upon it. An environment is mostly said to be non-feministic.</p><br>
                    </section>

                    <section>
                        <h3>The Nature of Environment:</h3>
                        <br>
                        <p>Features of Environment</p>
                        <br>
                        <p>As per Russell and Norvig, an environment can have various features from the point of view of an agent:</p>
                        <ul>
                            <li><strong>Fully observable vs Partially Observable:</strong><br>
                            If an agent sensor can sense or access the complete state of an environment at each point of time then it is a fully observable environment, else it is partially observable.
                            A fully observable environment is easy as there is no need to maintain the internal state to keep track history of the world.
                            An agent with no sensors in all environments then such an environment is called as unobservable.</li>
                            <br>
                            <li><strong>Deterministic vs Stochastic:</strong><br>
                            If an agent's current state and selected action can completely determine the next state of the environment, then such environment is called a deterministic environment.
                            A stochastic environment is random in nature and cannot be determined completely by an agent.
                            In a deterministic, fully observable environment, agent does not need to worry about uncertainty.</li>
                            <br>
                            <li><strong>Episodic vs Sequential:</strong><br>
                            In an episodic environment, there is a series of one-shot actions, and only the current percept is required for the action.
                            However, in Sequential environment, an agent requires memory of past actions to determine the next best actions.</li>
                            <br>
                            <li><strong>Single-agent vs Multi-agent:</strong><br>
                            If only one agent is involved in an environment, and operating by itself then such an environment is called single agent environment.
                            However, if multiple agents are operating in an environment, then such an environment is called a multi-agent environment.
                            The agent design problems in the multi-agent environment are different from single agent environment.</li>
                            <br>
                            <li><strong>Static vs Dynamic:</strong><br>
                            If the environment can change itself while an agent is deliberating then such environment is called a dynamic environment else it is called a static environment.
                            Static environments are easy to deal because an agent does not need to continue looking at the world while deciding for an action.
                            However for dynamic environment, agents need to keep looking at the world at each action.
                            Taxi driving is an example of a dynamic environment whereas Crossword puzzles are an example of a static environment.</li>
                            <br>
                            <li><strong>Discrete vs Continuous:</strong><br>
                            If in an environment there are a finite number of percepts and actions that can be performed within it, then such an environment is called a discrete environment else it is called continuous environment.
                            A chess gamecomes under discrete environment as there is a finite number of moves that can be performed.
                            A self-driving car is an example of a continuous environment.</li>
                            <br>
                            <li><strong>Known vs Unknown:</strong><br>
                            Known and unknown are not actually a feature of an environment, but it is an agent's state of knowledge to perform an action.
                            In a known environment, the results for all actions are known to the agent. While in unknown environment, agent needs to learn how it works in order to perform an action.
                            It is quite possible that a known environment to be partially observable and an Unknown environment to be fully observable.</li>
                            <br>
                            <li><strong>Accessible vs Inaccessible:</strong><br>
                            If an agent can obtain complete and accurate information about the state's environment, then such an environment is called an Accessible environment else it is called inaccessible.
                            An empty room whose state can be defined by its temperature is an example of an accessible environment.
                            Information about an event on earth is an example of Inaccessible environment.</li>
                        </ul>
                        <br>
                    </section>
                    
                    <section>
                        <h3>Structure of an AI Agent:</h3>
                        <br>
                        <p>The task of AI is to design an agent program which implements the agent function. The structure of an intelligent agent is a combination of architecture and agent program. It can be viewed as:</p>
                        <p>Agent = Architecture + Agent program</p>
                        <p>Following are the main three terms involved in the structure of an AI agent:</p>
                        <ul>
                            <li><strong>Architecture:</strong> Architecture is machinery that an AI agent executes on.</li>
                            <li><strong>Agent Function:</strong> Agent function is used to map a percept to an action. f:P* → A</li>
                            <li><strong>Agent program:</strong> Agent program is an implementation of agent function. An agent program executes on the physical architecture to produce function f.</li>
                        </ul>
                        <br>
                        <p><strong>PEAS Representation:</strong></p>
                        <p>PEAS is a type of model on which an AI agent works upon. When we define an AI agent or rational agent, then we can group its properties under PEAS representation model. It is made up of four words:</p>
                        <ul>
                            <li><strong>P:</strong> Performance measure</li>
                            <li><strong>E:</strong> Environment</li>
                            <li><strong>A:</strong> Actuators</li>
                            <li><strong>S:</strong> Sensors</li>
                        </ul>
                        <p>Here performance measure is the objective for the success of an agent's behavior.</p>
                        <br>
                        <p><strong>PEAS for self-driving cars:</strong></p>
                        <p>Let's suppose a self-driving car then PEAS representation will be:</p>
                        <ul>
                            <li><strong>Performance:</strong> Safety, time, legal drive, comfort</li>
                            <li><strong>Environment:</strong> Roads, other vehicles, road signs, pedestrian</li>
                            <li><strong>Actuators:</strong> Steering, accelerator, brake, signal, horn</li>
                            <li><strong>Sensors:</strong> Camera, GPS, speedometer, odometer, accelerometer, sonar</li>
                        </ul>
                        <br>
                    </section>
                </div>

                <div id="unit2" class="formatted-text">
                    <!-- Unit 2 text -->
                    <h2>UNIT 2: Problem-solving</h2>
                    <br>
                    <section>
                        <h3>2.1 Solving Problem by Searching:</h3>
                        <br>
                        <p>In Artificial Intelligence, search algorithms play a pivotal role, serving as a fundamental area of study. They are essential for problem-solving agents, contrasting with reflex agents that rely on direct state-to-action mappings. Problem-solving agents, unlike reflex agents, consider future actions and the desirability of outcomes, making them more adaptable to complex environments. These agents employ atomic representations of states, with no internal structure visible to the algorithms, in contrast to planning agents that utilize more advanced structured representations.</p><br>
                        <p>The discussion on problem-solving agents begins with precise definitions of problems and their solutions, accompanied by illustrative examples. General-purpose search algorithms are then introduced, ranging from uninformed algorithms, which lack information about the problem beyond its definition, to informed algorithms that perform better with guidance on where to search.</p><br>
                        <p>This chapter primarily focuses on task environments where the solution is a fixed sequence of actions, leaving the more complex scenarios for later discussions. Concepts such as asymptotic complexity and NP-completeness are introduced, offering readers insights into the computational challenges involved in problem-solving.</p><br>
                        <p>Overall, understanding search algorithms in AI is crucial for developing intelligent agents capable of navigating diverse environments efficiently. Through various search techniques, agents can explore and identify optimal solutions, paving the way for advancements in artificial intelligence and problem-solving applications.</p><br>
                    </section>
                    
                    <section>
                        <h3>2.2 Problem-solving agents:</h3>
                        <br>
                        <p>In Artificial Intelligence, problem-solving agents utilize search techniques as universal methods to tackle various problems effectively. These agents, also known as rational agents, rely on search algorithms to navigate through search spaces, beginning from a start state and progressing towards a goal state while adhering to defined search terminologies. Key components of search algorithms include the search space, start state, goal test, search tree, actions, transition model, path cost, solution, and optimal solution, with properties such as completeness, optimality, time complexity, and space complexity crucial for evaluating their efficiency.</p><br>
                        <p>Search algorithms can be categorized into uninformed (blind search) and informed (heuristic search) algorithms based on the presence of domain knowledge. Uninformed search methods operate without domain knowledge, employing brute-force approaches to explore search spaces, whereas informed search strategies utilize problem information to guide the search more efficiently. Examples of uninformed search algorithms include breadth-first search, depth-first search, and iterative deepening depth-first search, while informed search algorithms like greedy search and A* search leverage heuristics to find solutions effectively.</p><br>
                        <p>Problem-solving agents adopt goals to simplify decision-making processes, formulating goals based on current situations and performance measures. The process of problem formulation involves defining initial states, actions, transition models, goal tests, and path cost functions. Abstraction plays a vital role in problem formulation, simplifying state descriptions and action sequences to focus on relevant aspects of the problem while disregarding irrelevant details. Effective abstraction enables agents to handle complex real-world scenarios efficiently.</p><br>
                    </section>
                    
                    <section>
                        <h3>2.3 Example Problem:</h3>
                        <br>
                        <p>The provided text outlines various problem-solving approaches applied to both toy and real-world problems, highlighting examples such as the vacuum world, the 8-puzzle, the 8-queens problem, and more. Toy problems are simplified scenarios used to demonstrate problem-solving methods, whereas real-world problems reflect actual concerns and complexities.</p><br>
                        <p>In toy problems like the vacuum world and the 8-puzzle, discrete states and actions are defined, with clear initial states, actions, transition models, goal tests, and path costs. These problems serve as benchmarks for evaluating search algorithms in AI, with the 8-puzzle belonging to the NP-complete problem family.</p><br>
                        <p>The 8-queens problem, on the other hand, challenges placing queens on a chessboard without attacking each other. Different formulations exist, such as incremental and complete-state formulations, with varying state spaces and computational complexities.</p><br>
                        <p>Real-world problems like route-finding, touring, VLSI layout, robot navigation, and automatic assembly sequencing pose additional complexities. These problems involve continuous states and actions, with considerations for factors like time, cost, spatial constraints, and sensor errors.</p><br>
                    </section>

                    <section>
                        <h3>2.4 Searching for Solution:</h3>
                        <br>
                        <p>Search Tree Construction:</p><br>
                        <p>To solve a problem, search algorithms generate possible action sequences forming a search tree.</p><br>
                        <p>The initial state node serves as the root, with branches representing actions and nodes representing states.</p><br>
                        <p>Expansion involves applying legal actions to generate new states, resulting in child nodes.</p><br>
                        <p>Expansion and Frontier:</p><br>
                        <p>After expansion, new child nodes are added to the frontier for further consideration.</p><br>
                        <p>The frontier consists of leaf nodes available for expansion, and it separates explored and unexplored regions in the state space.</p><br>
                        <p>Search Strategy:</p><br>
                        <p>Search algorithms choose which state to expand next based on a search strategy.</p><br>
                        <p>The choice determines the direction of exploration and affects the efficiency of finding a solution.</p><br>
                        <p>Redundant Paths:</p><br>
                        <p>Redundant paths, including loopy paths, lead to unnecessary exploration in the search tree.</p><br>
                        <p>Algorithms should avoid redundant paths to prevent inefficiency and potential failure.</p><br>
                        <p>Redundant paths arise in reversible actions and must be managed appropriately.</p><br>
                        <p>Infrastructure for Search Algorithms:</p><br>
                        <p>Nodes represent states in the search tree and maintain essential information such as parent, action, and path cost.</p><br>
                        <p>Data structures like queues and hash tables facilitate efficient storage and retrieval of nodes and states.</p><br>
                        <p>Child nodes are generated from parent nodes based on applied actions and problem-specific functions.</p><br>
                        <p>Measuring Problem-Solving Performance:</p><br>
                        <p>Performance evaluation criteria include completeness, optimality, time complexity, and space complexity.</p><br>
                        <p>Complexity metrics depend on factors such as branching factor, depth, and maximum path length.</p><br>
                        <p>Search cost and total cost assess the effectiveness of search algorithms, considering both time and solution path length.</p><br>
                        <p>Tradeoffs and Total Cost:</p><br>
                        <p>Total cost combines search cost and solution path cost, allowing for tradeoffs between computational effort and solution quality.</p><br>
                        <p>Agents may optimize their decisions based on total cost, balancing the benefits of further computation against solution improvement.</p><br>
                    </section>
                    
                    <section>
                        <h3>2.4 Uninformed Search Strategies:</h3>
                        <br>
                        <p>This section introduces the concept of uninformed search, also known as blind search, where search strategies have no additional information about states beyond what's provided in the problem definition. The strategies can only generate successors and determine whether a state is a goal or not.</p><br>
                        <p><strong>Breadth-first Search (BFS)</strong></p><br>
                        <p>BFS expands nodes level by level, starting from the root node. It explores all nodes at a given depth before moving to the next level. BFS uses a FIFO queue to maintain the frontier, ensuring that nodes at shallower levels are expanded first. It guarantees completeness and optimality if the path cost is nondecreasing.</p><br>
                        <p><strong>Uniform-cost Search</strong></p><br>
                        <p>Uniform-cost search expands nodes based on their path costs, always choosing the node with the lowest path cost from the frontier. It maintains a priority queue ordered by path cost. Uniform-cost search is optimal and complete when all step costs are equal.</p><br>
                        <p><strong>Depth-first Search (DFS)</strong></p><br>
                        <p>DFS always expands the deepest node in the current frontier. It uses a LIFO queue, exploring the deepest unexpanded node first. DFS can be implemented as either graph search or tree search. It's not complete or optimal but has lower space complexity compared to BFS.</p><br>
                        <p><strong>Depth-limited Search</strong></p><br>
                        <p>Depth-limited search sets a predetermined depth limit to avoid infinite paths in infinite state spaces. It's a modified version of DFS where nodes beyond the depth limit are treated as having no successors. Depth-limited search can be incomplete and nonoptimal depending on the chosen depth limit.</p><br>
                        <p><strong>Iterative Deepening Depth-first Search (IDDFS)</strong></p><br>
                        <p>IDDFS gradually increases the depth limit from 0 until a solution is found. It combines the advantages of DFS and BFS, maintaining modest memory requirements while guaranteeing completeness and optimality. IDDFS repeatedly applies depth-limited search with increasing limits until a solution is found.</p><br>
                        <p><strong>Bidirectional Search</strong></p><br>
                        <p>Bidirectional search runs two simultaneous searches, one forward from the initial state and one backward from the goal. The goal is to meet in the middle, reducing the search space. Bidirectional search is advantageous in terms of time complexity but requires substantial memory due to maintaining frontiers from both directions.</p><br>
                    </section>

                    <section>
                        <h3>2.5 Informed Search Strategies:</h3>
                        <br>
                        <p>So far we have talked about the uninformed search algorithms which looked through search space for all possible solutions of the problem without having any additional knowledge about search space. But informed search algorithm contains an array of knowledge such as how far we are from the goal, path cost, how to reach to goal node, etc. This knowledge help agents to explore less to the search space and find more efficiently the goal node.</p><br>
                        <p>The informed search algorithm is more useful for large search space. Informed search algorithm uses the idea of heuristic, so it is also called Heuristic search.</p><br>
                        <p>In the informed search we will discuss two main algorithms which are given below:</p><br>
                        <p><strong>Best First Search Algorithm(Greedy search)</strong></p><br>
                        <p>Selects the path that seems best at each step based on heuristic function h(n).</p><br>
                        <p>Combines advantages of depth-first and breadth-first search.</p><br>
                        <p>Utilizes a priority queue.</p><br>
                        <p>Not optimal, can behave like an unguided depth-first search.</p><br>
                        <p>Time Complexity: O(b^m),</p><br>
                        <p>Space Complexity: O(b^m).</p><br>
                        <p>Incomplete.</p><br>
                        <p>Example: Traversing a search problem using the greedy best-first search algorithm.</p><br>
                        <p><strong>A* Search Algorithm</strong></p><br>
                        <p>Uses heuristic function h(n) and cost g(n) to find the shortest path through the search space.</p><br>
                        <p>Combines features of Uniform-Cost Search (UCS) and greedy best-first search.</p><br>
                        <p>Optimal and complete.</p><br>
                        <p>More complex than other algorithms.</p><br>
                        <p>Not always produces the shortest path.</p><br>
                        <p>Memory-intensive for large-scale problems.</p><br>
                        <p>Time Complexity: O(b^d), Space Complexity: O(b^d).</p><br>
                        <p>Example: Traversing a graph using the A* algorithm.</p><br>
                    </section>
                    
                    <section>
                        <h3>2.6 Heuristics function:</h3>
                        <br>
                        <p>Heuristic in Informed Search:</p><br>
                        <p>Heuristic function estimates the distance from the current state to the goal.</p><br>
                        <p>It's denoted as h(n) and always yields a positive value.</p><br>
                        <p>While not always providing the best solution, it ensures a good solution in reasonable time.</p><br>
                        <p><strong>Admissibility :</strong> h(n) ≤ h ∗ (n), where h∗(n) is the estimated cost.</p><br>
                        <p><strong>Pure Heuristic Search:</strong></p><br>
                        <p>Simplest form of heuristic search algorithms.</p><br>
                        <p>It expands nodes based on their heuristic value  h(n).</p><br>
                        <p>Maintains OPEN and CLOSED lists.</p><br>
                        <p>CLOSED list contains expanded nodes, while OPEN contains unexpanded ones.</p><br>
                        <p>Each iteration expands the node with the lowest heuristic value.</p><br>
                        <p>Generates successors of the expanded node and adds it to the CLOSED list.</p><br>
                        <p>Continues until a goal state is found.</p><br>
                    </section>
                    
                    <section>
                        <h3>2.7 Defining Constraint Satisfaction Problem:</h3>
                        <br>
                        <p>Constraint Satisfaction Problems (CSPs) are a fundamental type of AI problem where the objective is to find values for variables that satisfy a set of constraints.</p><br>
                        <p>These problems are common in resource allocation, planning, scheduling, and decision-making tasks in AI. CSPs consist of three main components: variables, domains, and constraints.</p><br>
                        <p>Variables represent the entities that need to be determined, while domains define the possible values that variables can take. Constraints govern how variables relate to each other, restricting the permissible combinations of values.</p><br>
                        <p>CSPs are typically represented by a finite set of variables, non-empty domains for each variable, and a set of constraints.</p><br>
                        <p>CSP algorithms aim to systematically explore the solution space until a solution satisfying all constraints is found. The backtracking algorithm is a depth-first search method that iteratively assigns values to variables and backtracks when a constraint violation is encountered. Forward-checking, a variant of backtracking, reduces the search space by applying local consistency to eliminate inconsistent values.</p><br>
                        <p>Additionally, constraint propagation algorithms use local consistency and inference to propagate constraints between variables and remove inconsistent values from domain sets. These algorithms condense the search space by iteratively enforcing constraints.</p><br>
                    </section>
                    
                    <section>
                        <h3>2.8 Constraint propagation: Inference in CSPs:</h3>
                        <br>
                        <p>In Constraint Satisfaction Problems (CSPs), inference techniques utilize constraints to deduce which variable/value pairs are consistent and which are not.</p><br>
                        <p>These techniques include node consistency, arc consistency, path consistency, and k-consistency. Constraint propagation is a fundamental approach in CSPs, where constraints are used to reduce the number of legal values for a variable, subsequently impacting the legal values for other variables.</p><br>
                        <p>Local consistency, a key concept in CSPs, ensures that constraints are satisfied locally within the problem network.</p><br>
                        <p>Node consistency ensures that all values in a variable's domain satisfy its unary constraint. A network is node-consistent when every variable in the network meets this criterion.</p><br>
                        <p>Arc consistency, on the other hand, ensures that every value in a variable's domain satisfies its binary constraints.</p><br>
                        <p>A network achieves arc consistency when every variable is arc-consistent with every other variable, tightening down the domains using the binary constraints.</p><br>
                        <p>In the context of Sudoku, a popular CSP example, each square in the puzzle represents a variable, with its domain initially containing values from 1 to 9.</p><br>
                        <p>Pre-filled squares have domains consisting of single values, while empty squares have domains with all possible values.</p><br>
                        <p>The constraints in Sudoku, such as the "AllDiff" constraint, ensure that each row, column, and box of 9 squares contains distinct values.</p><br>
                        <p>In summary, inference techniques like node and arc consistency, along with constraint propagation, play crucial roles in solving CSPs.</p><br>
                        <p>These techniques help reduce the search space by eliminating inconsistent variable/value pairs, leading to efficient solutions in various real-world applications.</p><br>
                    </section>

                    <section>
                        <h3>2.9 Backtracking search for CSPs:</h3>
                        <br>
                        <p>The backtracking search algorithm is a core method for solving Constraint Satisfaction Problems (CSPs) in Artificial Intelligence. It systematically explores potential solutions by selecting variables, assigning values, and checking constraints.</p><br>
                        <p>This process continues recursively until a solution is found or until it determines that no solution exists. The algorithm ensures completeness, meaning it will find a solution if one exists within the given constraints.</p><br>
                        <p>However, its efficiency can degrade in scenarios with a large number of variables and constraints due to its exponential time complexity.</p><br>
                        <p>Nevertheless, its systematic approach and guarantee of completeness make it an essential tool for tackling CSPs in engineering exams. Understanding its principles, steps, advantages, and limitations is crucial for success in such exams.</p><br>
                    </section>
                    
                    <section>
                        <h3>2.10 Local Search for CSPs:</h3>
                        <br>
                        <p>Local search algorithms, particularly within Constraint Satisfaction Problems (CSPs), offer heuristic approaches for navigating solution spaces incrementally. They prioritize the current state and iteratively move towards neighboring states, aiming to satisfy problem constraints. This strategy proves valuable in scenarios where exhaustive exploration is impractical or when finding a complete solution is unnecessary.</p><br>
                        <p><strong>Key Components:</strong></p><br>
                        <p><strong>Initial State:</strong> Local search begins with an initial variable assignment, serving as the starting point.</p><br>
                        <p><strong>Objective Function:</strong> Evaluates the quality of assignments based on constraint satisfaction.</p><br>
                        <p><strong>Neighbourhood Function:</strong> Defines neighboring states reachable from the current assignment.</p><br>
                        <p><strong>Move or Transition:</strong> Determines how to transition from the current state to a neighboring state.</p><br>
                        <p><strong>Termination Condition:</strong> Specifies when to stop the search, based on solution quality or iteration count.</p><br>
                        <p><strong>Operation of Local Search:</strong></p><br>
                        <p>Initialization: Starts with an initial assignment.</p><br>
                        <p>Evaluation: Measures assignment quality using the objective function.</p><br>
                        <p>Neighbourhood Exploration: Generates neighboring states.</p><br>
                        <p>Transition: Moves to a selected neighboring state.</p><br>
                        <p>Iteration and Termination: Continues until termination conditions are met.</p><br>
                        <p><strong>Variants of Local Search:</strong></p><br>
                        <p>Hill Climbing: Progresses towards the best neighboring state but may get stuck in local optima.</p><br>
                        <p>Simulated Annealing: Accepts inferior solutions probabilistically to escape local optima.</p><br>
                        <p>Tabu Search: Prevents revisiting previous states to avoid cycling.</p><br>
                        <p>Genetic Algorithms: Explores solution spaces based on evolutionary principles.</p><br>
                        <p>Advantages include effectiveness for problems with extensive solution spaces and avoidance of exhaustive exploration. However, limitations include no guarantee of finding the optimal solution and sensitivity to initial assignments and neighborhood function choice.</p><br>
                    </section>
                    
                    <section>
                        <h3>2.11 Structure of Problem:</h3>
                        <br>
                        <p>In the domain of Artificial Intelligence, understanding the structure of a problem is crucial for devising effective solutions. This structure comprises several key components that delineate the problem's context, goals, constraints, and potential solution space.</p><br>
                        <p>The initial state serves as the starting point, providing the baseline configuration from which the problem-solving process commences. It sets the stage for subsequent actions and transformations.</p><br>
                        <p>Conversely, the goal state represents the ultimate objective that the problem-solving agent or algorithm aims to achieve. Attaining the goal state signifies successful completion of the problem-solving task.</p><br>
                        <p>Operators or actions define the permissible transitions between states within the problem space. These actions enable the agent to navigate through various states, exploring different pathways towards the goal.</p><br>
                        <p>Constraints impose limitations or rules on the problem, dictating which states or transitions are allowed. These constraints ensure that the problem-solving process adheres to specified criteria and constraints, constraining the solution space accordingly.</p><br>
                        <p>The space of solutions encompasses all feasible states or configurations that could lead from the initial state to the goal state, while satisfying the problem's constraints. It represents the entirety of potential solutions that the problem-solving agent may explore.</p><br>
                    </section>

                    <section>
                        <h3>2.12 Adversarial Search:</h3>
                        <br>
                        <p>Adversarial search, also known as game playing, involves multiple agents with conflicting goals exploring the same search space. Each agent acts as an opponent to the others, aiming to maximize its performance while hindering its adversaries. In multi-agent environments, agents must consider not only their own actions but also those of their opponents. Adversarial search strategies, like minimax and alpha-beta pruning, are used to navigate decision trees efficiently. Understanding adversarial search is crucial for designing intelligent systems in various domains, such as game-playing agents and autonomous vehicles.</p><br>
                    </section>
                    
                    <section>
                        <h3>2.13 Optimal Decision in Games:</h3>
                        <br>
                        <p>The Mini-max algorithm is a decision-making technique in game theory and Artificial Intelligence used to determine optimal moves in adversarial games. It operates by exploring the entire game tree through a depth-first search, with two players, a Maximizer, and a Minimizer, competing against each other. The Maximizer aims to maximize its score, while the Minimizer aims to minimize it. By recursively evaluating terminal states and backtracking, the algorithm computes the optimal decision for the current game state.</p><br>
                        <p>In the Mini-max algorithm, the entire game tree is traversed, evaluating each terminal node to determine its utility value. The Maximizer selects the node with the highest utility value, while the Minimizer chooses the node with the lowest utility value. This process continues until the algorithm reaches the root node, representing the optimal move for the player.</p><br>
                        <p>While Mini-max is complete and optimal, ensuring a solution is found if it exists and maximizing performance against an optimal opponent, it suffers from exponential time complexity, especially in complex games like Chess or Go. The branching factor and depth of the game tree contribute to its computational inefficiency. To address this limitation, techniques like alpha-beta pruning are employed to reduce the search space and improve efficiency.</p><br>
                    </section>
                    
                    <section>
                        <h3>2.14 Alpha-Beta Pruning:</h3>
                        <br>
                        <p>Alpha-beta pruning is a refinement of the Mini-max algorithm used in adversarial games. It optimizes the search tree by selectively eliminating branches that are unlikely to affect the final decision. This pruning is based on two parameters, alpha and beta, which represent the best choices found so far along the Maximizer and Minimizer paths. By maintaining bounds on possible outcomes, the algorithm reduces the search space without compromising accuracy. Alpha-beta pruning operates recursively, updating alpha and beta values during traversal to determine which nodes to prune. The efficiency of alpha-beta pruning relies on move ordering strategies to prioritize the evaluation of more promising nodes. Overall, it significantly improves the efficiency of Mini-max search, making it suitable for complex games with large search spaces.</p><br>
                    </section>
                    
                </div>

                <div id="unit3" class="formatted-text">
                    <!-- Unit 3 text -->
                    <h2>UNIT 3: Knowledge & Reasoning </h2>
                    <br>
                    <section>
                        <h3>3.1 Knowledge Representation issues:</h3>
                        <br>
                        <p>In AI, knowledge representation involves structuring information for machine understanding and problem-solving. Key issues include expressiveness, ensuring adequate representation of real-world complexity, and formalism, selecting clear representation languages like predicate logic.</p><br>
                        <p>Completeness and soundness ensure all necessary knowledge is represented accurately without contradictions. Scalability and efficiency ensure representation schemes can handle large amounts of data without computational overload.</p><br>
                        <p>Integration of diverse knowledge sources, handling uncertainty and incompleteness, and creating ontologies for semantic clarity are essential. Representations must also adapt to dynamic environments and be understandable by humans for validation and trust.</p><br>
                        <p>In summary, AI knowledge representation must balance expressiveness, efficiency, and adaptability while ensuring completeness, soundness, and human interpretability.</p><br>
                    </section>
                    
                    <section>
                        <h3>3.2 Representation and Mapping:</h3>
                        <br>
                        <p>Representation and mapping play vital roles in Artificial Intelligence (AI), facilitating the organization and utilization of knowledge for reasoning and decision-making.</p><br>
                        <p>Representation involves structuring information into a format comprehensible by AI systems, utilizing formalisms like logic, graphs, or rules. Key aspects include structured organization, abstraction to simplify complexities, expressiveness to capture essential features, and formal languages such as logic or semantic networks.</p><br>
                        <p>Mapping, on the other hand, establishes connections between different domains or concepts, enabling the transfer of knowledge and understanding relationships. It involves linking entities, transferring knowledge across representations, understanding relationships, and translating information between formats.</p><br>
                        <p>These concepts are crucial in AI for reasoning, decision-making, and problem-solving. Effective representation enables machines to perform tasks like reasoning and inference, while clear mappings aid in making informed decisions and modeling complex problems.</p><br>
                    </section>
                    
                    <section>
                        <h3>3.3 Approaches to Knowledge Representation:</h3>
                        <br>
                        <p>Approaches to knowledge representation in Artificial Intelligence (AI) encompass various methodologies and formalisms aimed at structuring and encoding knowledge for AI systems. These approaches include logical or propositional representation, semantic networks and frames, ontologies and knowledge graphs, rule-based systems, object-oriented representations, probabilistic representations, and connectionist approaches.</p><br>
                        <p>Logical representation involves predicate logic, first-order logic, and modal logic for expressing facts, relationships, and rules in a formal manner. Semantic networks and frames utilize nodes and arcs to represent relationships between entities, with frames providing a more structured organization. Ontologies and knowledge graphs define hierarchical models and graph-based structures for representing concepts and relationships within domains.</p><br>
                        <p>Rule-based systems use production rules and expert systems to trigger actions or inferences based on specific conditions. Object-oriented representation applies concepts from object-oriented programming to model entities as objects with properties and behaviors, while probabilistic representations, such as Bayesian networks and Markov models, handle probabilistic relationships and state transitions.</p><br>
                        <p>Connectionist approaches, like neural networks, learn from patterns and examples, utilizing interconnected nodes to model complex patterns. Each approach offers varying degrees of expressiveness, scalability, and effectiveness for reasoning and inference in AI systems, depending on the type of knowledge and domain requirements.</p><br>
                    </section>
                    
                    <section>
                        <h3>3.4 Issues in Knowledge Representation:</h3>
                        <br>
                        <p>Issues in knowledge representation within Artificial Intelligence (AI) encompass challenges related to structuring, organizing, and encoding knowledge in a manner that AI systems can effectively comprehend and utilize. These issues are crucial for building AI systems capable of accurately modeling real-world knowledge and performing various tasks.</p><br>
                        <p>Expressiveness and Representation Formalism: Finding a representation formalism that adequately captures the complexity of real-world knowledge and selecting appropriate formal languages or structures are key challenges.</p><br>
                        <p>Completeness and Soundness: Ensuring that representation schemes accommodate all necessary knowledge for the domain and accurately reflect knowledge without contradictions are essential aspects.</p><br>
                        <p>Scalability and Efficiency: Representations should scale efficiently with growing knowledge volumes and be processable for reasoning, inference, and retrieval tasks.</p><br>
                        <p>Integration of Different Knowledge Sources: Integrating knowledge from various sources into a unified representation and merging structured, semi-structured, and unstructured data require thoughtful design.</p><br>
                        <p>Uncertainty and Incompleteness: Handling uncertain or probabilistic information and representing incomplete knowledge are crucial for effective reasoning and decision-making.</p><br>
                        <p>Ontologies and Semantic Ambiguity: Creating ontologies for shared meaning across systems and resolving semantic ambiguity in terms or concepts are important for clear interpretation.</p><br>
                        <p>Dynamic and Adaptive Knowledge: Representations should adapt to changing knowledge or environments, and mechanisms for learning new knowledge or modifying existing representations based on experience are necessary.</p><br>
                        <p>Human Understandability: Representations should be understandable by humans for validation, debugging, and trust purposes, ensuring interpretability even with complex representations.</p><br>
                    </section>

                    <section>
                        <h3>3.5 Using Predicate logic: Presenting simple fact in logic:</h3>
                        <br>
                        <p>Predicate logic is a formal language utilized in AI and logic-based systems to represent knowledge and relationships logically. It extends propositional logic by introducing constants and predicates. Constants represent specific objects, while predicates denote relationships or properties attributed to objects.</p><br>
                        <p>For instance, "Likes(x, y)" signifies that 'x' likes 'y,' where 'x' and 'y' are variables representing objects. Simple facts like "Alice likes Bob" can be expressed as "Likes(Alice, Bob)," with 'Likes' as the predicate and 'Alice' and 'Bob' as constants.</p><br>
                        <p>Predicates can take variables as arguments, enabling more general statements. Multiple facts can be represented using logical conjunctions (AND) or disjunctions (OR).</p><br>
                        <p>For example, "Alice likes Bob" AND "Bob likes Carol" is represented as "Likes(Alice, Bob) AND Likes(Bob, Carol)," while "Alice likes Bob" OR "Alice likes Carol" is denoted by "Likes(Alice, Bob) OR Likes(Alice, Carol)."</p><br>
                        <p>Quantifiers, such as the universal quantifier (∀) and existential quantifier (∃), express the scope of variables. The universal quantifier indicates that a statement holds for all objects, as in ∀x Likes(Alice, x), while the existential quantifier signifies that a statement holds for at least one object, as in ∃x Likes(Alice, x).</p><br>
                        <p>Predicate logic provides a powerful framework for representing and reasoning about knowledge in AI systems.</p><br>
                    </section>
                    
                    <section>
                        <h3>3.6 Representing instant and ISA relationship:</h3>
                        <br>
                        <p>In the realm of Artificial Intelligence (AI), understanding the 'is-a' (ISA) relationship and instances is crucial for structuring knowledge about categories and their specific instances. This concept establishes hierarchical connections between entities based on class-subclass associations, portraying inheritance relationships.</p><br>
                        <p>For instance, "Car is a Vehicle" and "Rose is a Flower" exemplify subclass instances inheriting properties from their superclass categories. Representation of the ISA relationship typically involves organizing information hierarchically, with superclass categories like 'Vehicle' and 'Flower' containing subclass instances such as 'Car,' 'Truck,' 'Rose,' and 'Tulip.'</p><br>
                        <p>Instances, on the other hand, refer to specific objects falling under a particular category or class. For instance, an instance of 'Car' might possess attributes like make, model, color, and year, while an instance of 'Rose' could have characteristics such as color, petal count, and fragrance.</p><br>
                        <p>Understanding the 'is-a' relationship and instances in AI is crucial for organizing knowledge effectively, facilitating reasoning, classification, and identification of relationships.</p><br>
                    </section>
                    
                    <section>
                        <h3>3.7 Computable Functions and predicates:</h3>
                        <br>
                        <p><strong>Computable Functions:</strong></p><br>
                        <p>Computable functions are mathematical functions that can be computed by a computational system using algorithms or rules.</p><br>
                        <p>They are characterized by Turing completeness, meaning they can be computed by a Turing machine.</p><br>
                        <p>These functions are associated with deterministic algorithms, producing consistent outputs for the same inputs.</p><br>
                        <p>Examples include basic arithmetic operations (addition, subtraction, multiplication), trigonometric functions, and exponentiation.</p><br>
                        <p>Computable functions are represented using mathematical formulas or expressions and can be evaluated by algorithms or programs.</p><br>
                        <p><strong>Computable Predicates:</strong></p><br>
                        <p>Computable predicates are logical statements or conditions that can be evaluated to either true or false by an algorithmic process.</p><br>
                        <p>They represent relationships, conditions, or properties about entities within a domain.</p><br>
                        <p>Predicates involve logical operations and are evaluated based on certain criteria.</p><br>
                        <p>Examples include questions like "Is X greater than Y?" or "Is this object a member of a certain category?"</p><br>
                        <p>Similar to computable functions, computable predicates are associated with algorithms for evaluation.</p><br>
                        <p><strong>Significance in AI:</strong></p><br>
                        <p>Logical Reasoning: Computable functions and predicates are vital in logical reasoning and decision-making within AI systems.</p><br>
                        <p>Predicate Logic in Representing Knowledge: Predicates play a significant role in representing relationships and constraints in knowledge representation systems.</p><br>
                        <p>AI Algorithms: Computable functions are essential in various AI algorithms for tasks such as optimization, search, and pattern recognition.</p><br>
                    </section>
                    
                    <section>
                        <h3>3.8 Resolution:</h3>
                        <br>
                        <p>Resolution in AI:</p>
                        <p>Resolution is a theorem proving technique developed by mathematician John Alan Robinson in 1965. It is used to prove conclusions from given statements by building refutation proofs, which are proofs by contradictions. The technique operates efficiently on conjunctive normal form (CNF) or clausal form.</p><br>
                        <p><strong>Key Concepts:</strong></p><br>
                        <p><strong>Clause:</strong> A clause is a disjunction of literals, representing an atomic sentence. It's also known as a unit clause.</p><br>
                        <p><strong>Conjunctive Normal Form (CNF):</strong> Sentences represented as a conjunction of clauses.</p><br>
                        <p><strong>Resolution Rule:</strong> Involves resolving two clauses by identifying complementary literals and unifying them.</p><br>
                        <p><strong>Example:</strong></p><br>
                        <p>Consider two clauses: [Animal(g(x)) V Loves(f(x), x)] and [￢Loves(a, b) V ￢Kills(a, b)]. Complementary literals are Loves(f(x), x) and ￢Loves(a, b), which can be unified to generate a resolvent clause: [Animal(g(x)) V ￢Kills(f(x), x)].</p><br>
                        <p><strong>Steps for Resolution:</strong></p><br>
                        <ol>
                            <li>Convert facts into first-order logic.</li>
                            <li>Convert FOL statements into CNF.</li>
                            <li>Negate the statement that needs to be proved (proof by contradiction).</li>
                            <li>Draw resolution graph and perform unification.</li>
                        </ol><br>
                    </section>
                    
                    <section>
                        <h3>3.9 Natural Deduction:</h3>
                        <br>
                        <p>Natural Deduction in AI and Logic:</p><br>
                        <p>Natural deduction is a formal system utilized in logic and AI for reasoning, theorem proving, and logical inference. It facilitates deductive reasoning by employing rules of inference in a structured, step-by-step manner.</p><br>
                        <p><strong>Core Elements:</strong></p><br>
                        <p><strong>Assumptions (Hypotheses):</strong> The proof begins with assumptions or hypotheses, serving as starting points.</p><br>
                        <p><strong>Inference Rules:</strong> Natural deduction employs rules dictating how to move from assumptions to conclusions, facilitating the derivation of new statements.</p><br>
                        <p><strong>Example of Inference Rules:</strong></p><br>
                        <ul>
                            <li><strong>Introduction Rules:</strong> These introduce new logical connectives or quantifiers. For instance, ∧-Introduction introduces conjunctions like P ∧ Q if both P and Q are proven separately.</li>
                            <li><strong>Elimination Rules:</strong> These eliminate logical connectives or quantifiers. For example, ∧-Elimination allows deriving P or Q individually from a conjunction P ∧ Q.</li>
                        </ul><br>
                        <p><strong>Proof Process:</strong></p><br>
                        <ol>
                            <li>Assumption Introduction: Commence the proof by assuming a statement or hypothesis.</li>
                            <li>Application of Inference Rules: Utilize inference rules to derive new statements or justify logical steps, employing introduction and elimination rules for different logical connectives.</li>
                            <li>Derivation of Conclusions: Progress through the proof, deducing new statements and moving towards the intended conclusion.</li>
                            <li>Discharge of Assumptions: Once an assumption is discharged (closed), the proof concludes, and the derived conclusion is deemed valid based on the assumptions made.</li>
                        </ol><br>
                    </section>
                    
                    <section>
                        <h3>3.10 Representing knowledge using rules: Procedural verses declarative knowledge:</h3>
                        <br>
                        <p><strong>Knowledge Representation in AI:</strong> It involves structuring information for reasoning, decision-making, and problem-solving in AI systems.</p><br>
                        <p><strong>Procedural vs. Declarative Knowledge:</strong></p><br>
                        <p><strong>Procedural Knowledge:</strong> Focuses on defining step-by-step procedures to achieve a specific outcome.</p><br>
                        <p><strong>Declarative Knowledge:</strong> Describes facts, properties, or relationships between entities without detailing the steps.</p><br>
                        <p><strong>Forms of Representation:</strong></p><br>
                        <ul>
                            <li><strong>Procedural Knowledge:</strong> Represented using algorithms, rules, or instructions.</li>
                            <li><strong>Declarative Knowledge:</strong> Represented using facts, rules, assertions, or statements.</li>
                        </ul><br>
                        <p><strong>Comparison:</strong></p><br>
                        <ul>
                            <li><strong>Nature:</strong> Procedural focuses on "how," while declarative focuses on "what."</li>
                            <li><strong>Usage:</strong> Procedural suits algorithms and processes, while declarative is used in knowledge bases and reasoning systems.</li>
                            <li><strong>Flexibility and Understandability:</strong> Declarative knowledge is often more flexible and understandable than procedural knowledge.</li>
                        </ul><br>
                    </section>

                    <section>
                        <h3>3.11 Logic Programming:</h3>
                        <br>
                        <p>Logic Programming in AI: It's a paradigm using logic to express programs and represent knowledge, primarily using Prolog, a language for symbolic computation.</p><br>
                        <p><strong>Basics of Logic Programming:</strong></p><br>
                        <ul>
                            <li><strong>Declarative Style:</strong> Programs describe what should be done, leaving the system to determine how.</li>
                            <li><strong>Rule-Based Programming:</strong> Defined by a set of rules, facts, and relations governing system behavior.</li>
                            <li><strong>Logical Inference:</strong> Interprets programs as logical statements and uses inference for solutions.</li>
                        </ul><br>
                        <p><strong>Key Components:</strong></p><br>
                        <ul>
                            <li><strong>Facts:</strong> Represent basic knowledge or assertions about the problem domain.</li>
                            <li><strong>Rules:</strong> Conditional statements defining relationships or conditions.</li>
                            <li><strong>Queries:</strong> Questions posed to the system to seek information or solutions.</li>
                        </ul><br>
                        <p><strong>Prolog Language:</strong></p><br>
                        <ul>
                            <li><strong>Horn Clauses:</strong> Primary constructs with a head and body, resembling logical implications.</li>
                            <li><strong>Unification:</strong> Matches and binds variables to values for predicate evaluation.</li>
                        </ul><br>
                        <p><strong>Usage in AI:</strong></p><br>
                        <ul>
                            <li><strong>Knowledge Representation:</strong> Effective in modeling domains, rules, and relationships.</li>
                            <li><strong>Expert Systems:</strong> Utilized to represent expertise and reasoning.</li>
                            <li><strong>Natural Language Processing (NLP):</strong> Applied in certain NLP tasks for linguistic structure processing.</li>
                            <li><strong>Symbolic Computation:</strong> Used for tasks like theorem proving, puzzle solving, and symbolic manipulation.</li>
                        </ul><br>
                    </section>
                    
                    <section>
                        <h3>3.12 Forward verses Backward reasoning:</h3>
                        <br>
                        <p>Forward chaining as the name suggests, start from the known facts and move forward by applying inference rules to extract more data, and it continues until it reaches to the goal, whereas backward chaining starts from the goal, move backward by using inference rules to determine the facts that satisfy the goal.</p><br>
                        <p>Forward chaining is called a data-driven inference technique, whereas backward chaining is called a goal-driven inference technique.</p><br>
                        <p>Forward chaining is known as the down-up approach, whereas backward chaining is known as a top-down approach.</p><br>
                        <p>Forward chaining uses breadth-first search strategy, whereas backward chaining uses depth-first search strategy.</p><br>
                        <p>Forward and backward chaining both applies Modus ponens inference rule.</p><br>
                        <p>Forward chaining can be used for tasks such as planning, design process monitoring, diagnosis, and classification, whereas backward chaining can be used for classification and diagnosis tasks.</p><br>
                        <p>Forward chaining can be like an exhaustive search, whereas backward chaining tries to avoid the unnecessary path of reasoning.</p><br>
                        <p>In forward-chaining there can be various ASK questions from the knowledge base, whereas in backward chaining there can be fewer ASK questions.</p><br>
                        <p>Forward chaining is slow as it checks for all the rules, whereas backward chaining is fast as it checks few required rules only.</p><br>
                    </section>
                    
                    <section>
                        <h3>3.13 Matching:</h3>
                        <br>
                        <p><strong>Definition of Matching:</strong></p><br>
                        <p>Matching involves comparing two or more structures to identify similarities or differences. These structures can represent various objects, including physical entities, words or phrases, classes, concepts, or relations between entities.</p><br>
                        <p><strong>Applications of Matching:</strong></p><br>
                        <p>Matching is essential in a wide range of programs and AI applications, including speech recognition, natural language understanding, vision, learning, automated reasoning, planning, automatic programming, and expert systems.</p><br>
                        <p><strong>Types of Matching:</strong></p><br>
                        <ul>
                            <li><strong>Exact Matching:</strong> Compares structures for exact equality, where any difference leads to a failed match.</li>
                            <li><strong>Partial Matching:</strong> Permits transformations in patterns to achieve equality, allowing for variations or omissions in components.</li>
                            <li><strong>Fuzzy Matching:</strong> Considers an entity's degree of membership in one or more classes, suitable when boundaries between classes are not distinct.</li>
                        </ul><br>
                        <p><strong>Matching Techniques:</strong></p><br>
                        <p>Matching techniques vary based on factors such as representation scheme, matching criteria, choice of measure, and type of output required. Techniques may involve simple comparisons, unifications, or transformations of structures into a common schema before matching.</p><br>
                        <p><strong>Output of Matching:</strong></p><br>
                        <p>The output of the matching process can range from a simple yes or no response to a detailed annotation of similarities and differences between matched objects. It may include variable bindings, lists of similarities or differences, or overall measures of similarity.</p><br>
                        <p><strong>Factors Influencing Matching Algorithm:</strong></p><br>
                        <ul>
                            <li>Choice of representation scheme for objects being matched.</li>
                            <li>Criteria for matching (exact, partial, fuzzy, etc.).</li>
                            <li>Selection of a suitable measure for performing the match based on chosen criteria.</li>
                            <li>Type of match description required for output.</li>
                        </ul><br>
                    </section>

                    <section>
                        <h3>3.14 Control Knowledge:</h3>
                        <br>
                        <p>Control knowledge in Artificial Intelligence (AI) guides the reasoning, decision-making, and problem-solving processes of AI systems. It encompasses strategies, heuristics, search algorithms, problem-solving methods, and control parameters. Strategies and heuristics dictate actions, like prioritizing moves in a chess-playing AI. Search algorithms determine how solutions are found, balancing exploration and exploitation. Problem-solving methods select techniques like rule-based systems or neural networks. Control parameters adjust behavior, such as setting thresholds in machine learning algorithms.</p><br>
                        <p>Control knowledge is vital for adaptability, allowing AI systems to adjust strategies based on changing scenarios. It enhances efficiency and performance by selecting appropriate strategies or algorithms. It also encapsulates domain-specific expertise, aligning decisions with domain requirements. Examples include routing algorithms in network systems, strategies for game-playing AI, and decision-making in autonomous vehicles.</p><br>
                        <p>Challenges include optimization, balancing efficiency and accuracy, ensuring adaptability to varying conditions, and requiring deep domain expertise for effective design. In engineering exams, understanding control knowledge is crucial for designing AI systems tailored to specific tasks, optimizing performance, and addressing challenges effectively.</p><br>
                    </section>
                    
                </div>

                <div id="unit4" class="formatted-text">
                    <!-- Unit 4 text -->
                    <h2>UNIT 4: Probabilistic Reasoning</h2>
                    <br>
                    <section>
                        <h3>4.1 Representing Knowledge in an uncertain domain:</h3>
                        <br>
                        <p>Representing knowledge in uncertain domains involves various approaches to deal with uncertainty. Three primary methods discussed are probability theory, fuzzy logic, and truth maintenance systems.</p><br>
                        <p><strong>Probability Theory:</strong> Probability theory deals with sets of possible worlds, represented by a sample space (Ω). Each possible world (ω) is associated with a numerical probability (P(ω)). It allows for the calculation of probabilities for events like coin tosses or combinations of events. For example, the probability of two independent events occurring together is the product of their individual probabilities.</p><br>
                        <p><strong>Fuzzy Logic:</strong> Fuzzy logic addresses uncertainty by allowing for approximate reasoning. Unlike predicate logic and probability-based methods, fuzzy logic handles fuzzy quantifiers, providing a systematic framework for dealing with imprecise information. It subsumes predicate logic and probability theory, offering a comprehensive approach to uncertainty management.</p><br>
                        <p><strong>Truth Maintenance Systems (TMS):</strong> TMS records and maintains the reasons for program beliefs, allowing for assumption-making and belief revision when new information contradicts existing beliefs. It operates by storing the latest truth value of predicates, facilitating the adaptation of beliefs over time.</p><br>
                        <p>Additionally, Bayesian networks are introduced as a data structure to represent dependencies among variables in uncertain domains. These networks, represented as directed acyclic graphs, use conditional probability distributions to quantify the effect of parents on each node. Bayesian networks capture conditional independence relationships among variables, providing a concise representation of uncertainty in complex domains.</p><br>
                    </section>
                    
                    <section>
                        <h3>4.2 The semantics of Bayesian networks:</h3>
                        <br>
                        <p>Bayesian networks, fundamental in handling uncertainty, are probabilistic graphical models representing variables and their dependencies through directed acyclic graphs (DAGs). These networks, synonymous with Bayes networks or belief networks, find application in prediction, anomaly detection, diagnostics, and decision making in uncertain scenarios.</p><br>
                        <p>Their semantics can be understood in two ways: as a representation of the joint probability distribution or as an encoding of conditional independence statements.</p><br>
                        <p>The former view aids in constructing networks, while the latter assists in designing inference procedures. Constructing Bayesian networks involves determining node ordering and establishing conditional independence relationships, ensuring that each node is conditionally independent of its predecessors given its parents. This ensures network acyclicity and efficient representation.</p><br>
                        <p>The compactness of Bayesian networks is crucial for handling domains with numerous variables. Locally structured systems, where each variable interacts directly with a bounded number of others, enable efficient representation. Correct node ordering is pivotal for compactness; incorrect ordering may lead to redundant links and complex probability judgments.</p><br>
                        <p>Furthermore, the topological semantics of Bayesian networks imply conditional independence relationships, ensuring that nodes are independent of non-descendants given their parents. This concept, illustrated through the Markov blanket, underscores the network's ability to represent complex dependencies efficiently.</p><br>
                    </section>
                    
                    <section>
                        <h3>4.3 Dempster-Shafer theory:</h3>
                        <br>
                        <p>Dempster-Shafer Theory (DST), proposed by Arthur P. Dempster and Glenn Shafer, emerged as an evidence theory in response to limitations in Bayesian theory. Unlike Bayesian probability, which focuses on single evidence and struggles with describing ignorance, DST amalgamates all potential outcomes of a problem.</p><br>
                        <p>Illustrated through a murder mystery scenario, DST demonstrates how different combinations of suspects could have committed the crime. It utilizes sets of possible conclusions (P) where each conclusion must be mutually exclusive. The Power Set, containing 2^n elements, represents all possible subsets of the possible conclusions.</p><br>
                        <p>Mass function (m) interprets evidence for a set and assigns belief and plausibility based on subsets intersecting with the set. Belief in a set is the sum of masses of its subsets, while plausibility is the sum of masses of sets intersecting with it.</p><br>
                        <p>DST ensures that the probability of all events aggregates to 1, reducing ignorance as more evidence is added. Its combination rule facilitates the integration of various possibilities, leading to a reduction in the uncertainty interval.</p><br>
                        <p>Despite its advantages in representing diagnose hierarchies and providing freedom to consider evidence, DST's main disadvantage lies in its high computational effort due to dealing with 2^n sets.</p><br>
                    </section>

                    <section>
                        <h3>4.4 Fuzzy sets and fuzzy logics:</h3>
                        <br>
                        <p>Fuzzy logic, introduced by Lofti Zadeh in 1965, revolutionized problem-solving by accommodating uncertainty between true and false values. Unlike Boolean logic's binary approach, fuzzy logic allows for multiple truth values between 0 and 1, offering a flexible solution to real-life problems. Grounded in the Fuzzy Set Theory, it extends the range of possibilities beyond traditional computing paradigms.</p><br>
                        <p>Key characteristics of fuzzy logic include its flexibility, applicability to approximate or uncertain reasoning, and ability to handle nonlinear functions of arbitrary complexity. It emphasizes degrees of truth, reflecting the inherent uncertainty in many real-world scenarios. Fuzzy logic finds applications in diverse fields such as decision-making support systems, automotive control, defense, pattern recognition, and finance.</p><br>
                        <p>The architecture of a fuzzy logic system comprises four main components: Rule Base, Fuzzification, Inference Engine, and Defuzzification. Each component plays a crucial role in processing information and generating precise outputs. Fuzzification transforms crisp inputs into fuzzy values, while the Inference Engine matches inputs to predefined rules for decision-making. Defuzzification converts fuzzy outputs into crisp values for user acceptance.</p><br>
                        <p>Membership functions in fuzzy sets quantify linguistic terms by mapping elements to values between 0 and 1, enabling effective representation of fuzzy concepts. Fuzzy set operations such as union, intersection, and complementation facilitate the manipulation of fuzzy data, allowing for complex reasoning and decision-making.</p><br>
                        <p>Comparing classical set theory with fuzzy set theory highlights fundamental differences in their treatment of boundaries and uncertainty. While classical sets have sharp boundaries and exact membership values, fuzzy sets embrace ambiguity and partial membership, making them suitable for fuzzy controllers and systems requiring nuanced decision-making.</p><br>
                        <p>Advantages of fuzzy logic include its similarity to human reasoning, simplicity, efficiency in handling complex problems, and flexibility in rule modification. However, drawbacks such as slower runtime, potential inaccuracies, and the need for extensive testing limit its suitability for applications requiring high accuracy.</p><br>
                    </section>
                    
                    <section>
                        <h3>4.5 Planning: Overview</h3>
                        <br>
                        <p>Planning plays a crucial role in the realm of Artificial Intelligence (AI), serving as the logical framework guiding the actions of intelligent systems. It involves decision-making processes aimed at achieving specific goals, whether it's navigating a self-driving car, coordinating tasks in a smart city, or solving complex problems like the block-world puzzle.</p><br>
                        <p>In the planning process, a sequence of actions is devised, each with its preconditions and effects, forming the basis of plans. Two fundamental approaches to planning are Forward State Space Planning (FSSP) and Backward State Space Planning (BSSP). FSSP progresses from an initial state to a target state, while BSSP works backward from the goal to the initial state, minimizing the branching factor.</p><br>
                        <p>Efficient planning often necessitates combining features of both FSSP and BSSP, leading to strategies like Target Stack Planning, which optimally balances soundness and branching factor concerns. Target Stack Planning, utilized by algorithms such as STRIPS, employs a stack-based approach to iteratively achieve goals.</p><br>
                        <p>Moreover, non-linear planning techniques introduce flexibility by exploring various goal orderings, potentially yielding optimal solutions in terms of planning length. However, this method involves a larger search space and complex algorithms.</p><br>
                        <p>In practical application, planning systems encompass essential steps such as rule selection, problem condition calculation, solution detection, dead-end detection, and solution refinement. These steps ensure systematic and effective decision-making in AI systems.</p><br>
                        <p>Overall, planning in AI involves sophisticated algorithms and methodologies aimed at orchestrating actions towards predefined objectives, making it a cornerstone in the development of intelligent technologies and systems.</p><br>
                    </section>
                    
                    <section>
                        <h3>4.6 Components of Planning System:</h3>
                        <br>
                        <p>In the domain of artificial intelligence, planning systems are integral for problem-solving and decision-making processes. These systems consist of various components that orchestrate the transition from an initial problem state to a desirable goal state. Here's a breakdown of the key components:</p><br>
                        <p><strong>States:</strong> Planning systems decompose the world into environments defined by logical conditions and states. States represent specific configurations of the environment and serve as the foundation for defining the problem space. They are often viewed as conjunctions of positive literals, reflecting the current situation.</p><br>
                        <p><strong>Goal:</strong> The goal represents the desired end state of the planning process. It serves as a target for the system to reach, guiding the generation of moves through the problem space. Achieving the goal signifies the successful completion of the planning task, although reaching it may be challenging, especially in complex environments like games.</p><br>
                        <p><strong>Actions:</strong> Actions are the fundamental units of change in the planning process. They are defined by preconditions, specifying the conditions that must be met for the action to be executed, and effects, describing the changes that occur in the environment when the action is performed. Actions drive the transformation from one state to another.</p><br>
                        <p><strong>Precondition:</strong> Precondition represents the conditions that must be true in the current state for an action to be valid. It ensures that actions are executed in appropriate contexts, preventing unintended consequences.</p><br>
                        <p><strong>Effect:</strong> Effects denote the changes that occur in the environment when an action is executed successfully. They describe how the state transitions from the pre-action state to the post-action state, reflecting the impact of the action on the environment.</p><br>
                        <p><strong>Finding a Solution:</strong> A planning system aims to find a sequence of actions that transform the initial problem state into the goal state. This involves navigating through the problem space, generating and evaluating potential moves until a solution path is discovered. The representation of state descriptions influences the approach to solving the problem.</p><br>
                        <p><strong>Calculating the Dead State:</strong> During the search for a solution, the planning system must detect paths that lead to dead ends, i.e., states from which the goal state cannot be reached. This involves reasoning forward from the initial state or backward from the goal state, pruning paths that are unlikely to lead to a solution. Detecting dead ends optimizes the search process, focusing efforts on viable solution paths.</p><br>
                    </section>

                    <section>
                        <h3>4.7 Goal Stack Planning:</h3>
                        <br>
                        <p>Goal Stack Planning is a classical AI technique employed for achieving desired outcomes by decomposing overarching goals into a sequence of subgoals and actions. It operates on the principle of a stack data structure, organizing goals and subgoals in a last-in, first-out (LIFO) manner.</p><br>
                        <p><strong>Concept and Structure:</strong> In Goal Stack Planning, the main goal is broken down into smaller, manageable subgoals, forming a stack structure. Goals are stacked on top of each other, reflecting their hierarchical relationships.</p><br>
                        <p><strong>Planning Process:</strong> The process begins with an initial state, representing the current state of the environment. The final goal is placed on top of the goal stack. Goals are decomposed into subgoals and actions, and appropriate plans are generated to achieve them. Actions are selected and applied to move the state closer to the desired outcome. As goals are achieved, they are popped off the stack, and new subgoals may emerge. The process continues until the final goal is achieved or deemed unattainable.</p><br>
                        <p><strong>Advantages and Limitations:</strong> Advantages of Goal Stack Planning include its hierarchical structure, which simplifies complex problems, and its flexibility in exploring alternative plans. However, it may struggle with large search spaces and can be sensitive to the order of goal decomposition and action execution.</p><br>
                        <p><strong>Application:</strong> Goal Stack Planning has found applications in various AI systems, particularly in early AI planning systems and robotics for task planning and control.</p><br>
                    </section>
                    
                    <section>
                        <h3>4.8 Hierarchical Planning:</h3>
                        <br>
                        <p>Hierarchical planning in artificial intelligence is a strategic approach that organizes tasks into multiple levels of abstraction, enabling effective reasoning and planning in complex domains. It involves breaking down high-level goals into subgoals and actions, creating a hierarchy that allows decision-making at various levels of abstraction. This approach utilizes a tree or directed acyclic graph structure, with the high-level goal as the root node and lower-level tasks or actions as leaf nodes.</p><br>
                        <p><strong>Key components of hierarchical planning:</strong> High-level goals, task decomposition, planning hierarchy, plan generation at different levels, plan synthesis, plan execution, and plan adaptation. This comprehensive structure allows for organized and systematic problem-solving. The definition emphasizes breaking down complex tasks into smaller sub-tasks or actions, enhancing the efficiency of intelligent agents.</p><br>
                        <p><strong>Advantages of hierarchical planning:</strong> Scalability, flexibility, abstraction, reuse of plans, higher-level reasoning, and improved task organization. These benefits make it a valuable tool in various applications, such as robotics, autonomous systems, manufacturing, and transportation. However, hierarchical planning faces challenges like scalability issues, the complexity of the planning process, and difficulties in adapting to dynamic environments.</p><br>
                        <p><strong>Techniques employed in hierarchical planning:</strong> Decomposition, abstraction, task allocation, and plan integration. Decomposition techniques break down high-level goals, abstraction methods represent tasks at different abstraction levels, task allocation assigns tasks to appropriate agents, and plan integration combines plans for execution.</p><br>
                    </section>
                    
                </div>

                <div id="unit5" class="formatted-text">
                    <!-- Unit 5 text -->
                    <h2>UNIT 5: Natural Language Processing</h2>
                    <br>
                    <section>
                        <h3>5.1 Introduction:</h3>
                        <br>
                        <p>Natural Language Processing (NLP) is a vital subfield of Artificial Intelligence (AI) focused on enabling computers to understand, interpret, generate, and manipulate human languages. It plays a crucial role in various applications, including personal assistants, sentiment analysis, chatbots, and machine translation, by processing natural language data like text and speech.</p><br>
                        <p>NLP tasks encompass text and speech processing, text classification, language generation, and language interaction. Techniques such as tokenization, part-of-speech tagging, and sentiment analysis are commonly used to analyze and understand human language.</p><br>
                        <p>The working of NLP involves three main components: Speech Recognition, Natural Language Understanding (NLU), and Natural Language Generation (NLG). Speech recognition converts spoken language into text, while NLU focuses on understanding the meaning of words and sentences. NLG, on the other hand, converts machine-readable language into text or audible speech.</p><br>
                        <p>Technologies related to NLP include machine learning, natural language toolkits (NLTK), parsers, text-to-speech (TTS), and speech-to-text (STT) systems. These technologies are utilized in applications such as spam filters, algorithmic trading, question answering, and summarizing information from vast amounts of textual data.</p><br>
                        <p>NLP research is actively evolving, with recent advancements in deep learning, particularly in neural networks like Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), leading to significant improvements in NLP performance.</p><br>
                    </section>
                    
                    <section>
                        <h3>5.2 Syntactic Processing:</h3>
                        <br>
                        <p>Syntactic processing is a fundamental aspect of Natural Language Processing (NLP) that involves analyzing the grammatical structure of sentences to comprehend their meaning. Unlike lexical processing, which focuses on data cleaning and feature extraction, syntactic processing delves into understanding the roles played by individual words and their relationships within a sentence.</p><br>
                        <p>To illustrate, consider the example sentence "The cat sat on the mat." Syntactic processing would involve identifying key components such as nouns ("cat," "mat"), verbs ("sat"), and prepositions ("on"), and determining their respective roles in the sentence.</p><br>
                        <p>Syntactic processing comprises several steps, including tokenization, part-of-speech (PoS) tagging, parsing, and semantic analysis. Tokenization breaks down sentences into individual words or tokens, while PoS tagging identifies the part of speech of each token. Parsing involves analyzing the grammatical structure of sentences to identify subjects, verbs, and objects, while semantic analysis focuses on understanding the meaning of the sentence in context.</p><br>
                        <p>Various techniques, such as rule-based methods, statistical methods, and machine learning algorithms, are employed in syntactic processing, each with its strengths and weaknesses. The choice of technique depends on the specific task and available data.</p><br>
                        <p>Syntactic processing is critical for many NLP applications, including machine translation, sentiment analysis, and question-answering. Without accurate syntactic processing, computers struggle to comprehend the underlying meaning of human language.</p><br>
                    </section>
                    
                    <section>
                        <h3>5.3 Semantic Analysis:</h3>
                        <br>
                        <p>Semantic analysis is a crucial aspect of Natural Language Processing (NLP) that endeavors to decipher the meaning of natural language text by considering context, logical sentence structure, and grammar roles. It involves two primary components: lexical semantic analysis and compositional semantics analysis. Lexical semantic analysis focuses on understanding the meaning of individual words, while compositional semantics analysis delves into how combinations of words contribute to the overall meaning of a text.</p><br>
                        <p>Tasks within semantic analysis include word sense disambiguation and relationship extraction. Word sense disambiguation addresses the ambiguity of word meanings based on context, ensuring accurate interpretation. Relationship extraction involves identifying entities within a sentence and determining the relationships between them.</p><br>
                        <p>Key elements of semantic analysis include hyponymy, homonymy, synonymy, antonymy, polysemy, and meronomy, each contributing to a deeper understanding of word relationships and meanings. To represent textual information for machine interpretation, semantic systems utilize entities, concepts, relations, and predicates.</p><br>
                        <p>Various approaches to meaning representation include first-order predicate logic, semantic nets, frames, conceptual dependency, rule-based architecture, case grammar, and conceptual graphs. These approaches enable machines to interpret and represent textual information effectively.</p><br>
                        <p>Semantic analysis techniques serve different purposes, such as text classification and text extraction. Text classification involves labeling text based on insights gained, such as sentiment analysis, topic classification, and intent classification. Text extraction aims to extract specific information from text, including keyword extraction and entity extraction.</p><br>
                    </section>
                    
                    <section>
                        <h3>5.4 Discourse and pragmatic processing:</h3>
                        <br>
                        <p>Discourse and pragmatic processing in AI extend beyond literal language meanings, incorporating broader context, intentions, and shared knowledge between communicators. Discourse processing involves analyzing connected series of utterances to derive coherent interpretations, focusing on coherence, cohesion, anaphora resolution, coreference resolution, and discourse structure.</p><br>
                        <p>Pragmatic processing studies language in use, considering context, intentions, and implications of communicative acts. It encompasses speech acts, implicatures, presuppositions, and context and inference.</p><br>
                    </section>

                    <section>
                        <h3>5.5 Learning: Forms of Learning:</h3>
                        <br>
                        <p>Learning encompasses the process of converting experience into expertise or knowledge and can be broadly categorized into three types: supervised learning, unsupervised learning, and semi-supervised learning. Additionally, reinforcement learning is another form of learning where the system adjusts based on feedback to achieve a certain objective.</p><br>
                        <p><strong>Supervised learning</strong> involves learning from labeled data, where the objective is to find a general rule that maps inputs to outputs. Regression and classification are two common types of supervised learning, with examples including predicting real estate prices and classifying emails into spam and not-spam categories. Various algorithms like Logistic Regression, Neural Networks, and Support Vector Machines are employed in supervised learning tasks.</p><br>
                        <p><strong>Unsupervised learning</strong>, on the other hand, deals with unlabeled data, where the algorithm aims to find hidden patterns or group similar data points into logical clusters. It is commonly used for anomaly detection, fraud detection, and customer segmentation. Algorithms such as Kmeans, Random Forests, and Hierarchical Clustering are used in unsupervised learning tasks.</p><br>
                        <p><strong>Semi-supervised learning</strong> occurs when some learning samples are labeled while others are not, making use of both labeled and unlabeled data for training. It is applied in cases where acquiring a fully labeled dataset is expensive but labeling a small subset is more practical. For example, semi-supervised learning is used in remote sensing image analysis and oil exploration.</p><br>
                        <p><strong>Reinforcement learning</strong> involves learning from feedback to adjust to dynamic conditions and achieve a specific objective. Examples include self-driving cars and chess-playing algorithms like AlphaGo. In reinforcement learning, the system evaluates its performance based on feedback responses and adapts accordingly.</p><br>
                    </section>
                    
                    <section>
                        <h3>5.6 Inductive Learning:</h3>
                        <br>
                        <p>Inductive Learning Algorithm (ILA) is an iterative and inductive machine learning approach used to generate classification rules of the form "IF-THEN" from a set of examples. It addresses the need for a more generalized rule generation process compared to previous algorithms like ID3 and AQ, which lacked in rule generalization and efficiency.</p><br>
                        <p>The ILA iteratively constructs a set of classification rules by analyzing the provided examples. It begins by dividing the examples into subsets based on the possible values of the class attribute. Then, it proceeds through several steps, including attribute combination counting, rule generation, and subset processing, to derive the classification rules.</p><br>
                        <p>The ILA requires certain prerequisites for implementation, such as having examples listed in a table format and creating an initial rule set. The implementation involves steps like dividing the example table into subsets, counting attribute occurrences, marking rows, and generating rules based on the most frequent attribute combinations.</p><br>
                        <p>An illustrative example demonstrates the application of ILA to a dataset containing attributes like place type, weather, location, and decision. Through iterations, the ILA identifies attribute combinations and generates classification rules based on the observed patterns in the data.</p><br>
                        <p>The resulting set of rules provides insights into the conditions under which certain decisions are made based on the attributes' values. Each rule follows the IF-THEN format, specifying the attribute conditions that lead to a particular decision outcome.</p><br>
                    </section>
                    
                    <section>
                        <h3>5.7 Learning Decision Tree:</h3>
                        <br>
                        <p>Decision trees are a popular machine learning algorithm widely used for classification and regression tasks. They work by creating a model that predicts the value of a target variable based on simple decision rules learned from the data features.</p><br>
                        <p><strong>Construction of Decision Trees:</strong> Decision trees are constructed by recursively partitioning the dataset based on specific criteria until a stopping criterion is met. The process involves selecting the best attribute for splitting, splitting the dataset, and growing the tree.</p><br>
                        <p><strong>Splitting Criteria:</strong> Decision trees use criteria such as Information Gain (Entropy) and Gini Impurity to determine the attribute that provides the most information gain or reduces impurity the most when splitting the dataset.</p><br>
                        <p><strong>Recursive Partitioning:</strong> The dataset is recursively partitioned into subsets based on the selected attribute until a stopping criterion, such as maximum depth or minimum samples per leaf, is met.</p><br>
                        <p><strong>Tree Structure:</strong> Decision trees consist of nodes representing features or attributes, edges showing decision rules, and leaves representing the outcome (classification or regression value).</p><br>
                        <p><strong>Learning Process:</strong> The algorithm selects the best attribute for splitting based on information gain or impurity reduction, splits the dataset, and continues the process recursively until a stopping criterion is reached.</p><br>
                        <p><strong>Pruning (Optional):</strong> Pruning techniques may be applied after tree construction to prevent overfitting by removing nodes with little predictive power.</p><br>
                        <p><strong>Prediction Process:</strong> To make predictions, the data traverses through decision nodes following decision rules until reaching a leaf node, where the outcome is used as the prediction.</p><br>
                        <p><strong>Advantages:</strong> Decision trees are highly interpretable, handling non-linear relationships well, and can demonstrate feature importance for decision-making.</p><br>
                        <p><strong>Limitations:</strong> They can be prone to overfitting, sensitive to small variations in the data, and biased towards features with many levels.</p><br>
                        <p><strong>Applications:</strong> Decision trees find applications in various fields, including spam filtering, disease diagnosis, credit risk analysis, and regression tasks like predicting house prices and demand forecasting.</p><br>
                    </section>

                    <section>
                        <h3>5.8 Explanation-Based Learning:</h3>
                        <br>
                        <p>Explanation-Based Learning (EBL) is a branch of machine learning that efficiently solves complex problems by leveraging explanations from past experiences. Unlike traditional statistical methods, EBL algorithms integrate logical reasoning and domain knowledge to understand and tackle intricate issues effectively.</p><br>
                        <p>In EBL, specific situations and their solutions are analyzed, and the learned insights are applied to similar problems. The process involves a problem solver, generalizer, and operational pruner. The problem solver analyzes inputs, the generalizer derives solutions based on past knowledge, and the operational pruner refines the final concept.</p><br>
                        <p>The EBL hypothesis posits that systems can efficiently solve current problems if they have explanations for similar past problems. Learning through explanations is deemed more effective than learning through instances alone, as it harnesses existing knowledge and reasoning.</p><br>
                        <p>The standard approach to EBL involves problem identification, gathering of previously solved problems, extraction of underlying principles, and application of these principles to new problems. This systematic approach ensures efficient problem-solving based on past experiences.</p><br>
                        <p>EBL finds applications in diverse fields such as medical diagnosis, robot navigation, and fraud detection. For instance, in medical diagnosis, EBL algorithms can diagnose underlying causes based on symptoms analyzed from past instances.</p><br>
                    </section>
                    
                    <section>
                        <h3>5.9 Learning using relevance information:</h3>
                        <br>
                        <p>Learning using relevance information in AI is a crucial approach aimed at enhancing the efficiency and performance of machine learning models by leveraging the significance of data attributes or features. This method involves selecting, weighting, or transforming features based on their relevance to the target variable, thereby guiding the learning process to focus on the most informative aspects of the data.</p><br>
                        <p>Key methods include feature selection, feature weighting, dimensionality reduction, relevance feedback in information retrieval, and active learning. Feature selection involves identifying and selecting the most relevant features contributing significantly to the target variable, thus reducing dimensionality and improving model performance. Feature weighting assigns weights to features based on their relevance, prioritizing important features and diminishing the impact of less relevant ones.</p><br>
                        <p>Dimensionality reduction techniques like PCA and t-SNE help visualize data, speed up computation, and improve model performance by focusing on essential features. Relevance feedback in information retrieval systems adapts search results based on user feedback, enhancing the quality of search results. Active learning with relevance information minimizes annotation cost by querying for the most relevant data points to label, thereby learning with minimal labeled data.</p><br>
                        <p>Applications of learning using relevance information span various domains such as text classification, image processing, and recommendation systems. By focusing on relevant features, this approach improves model performance, ensures efficient resource utilization, and enhances interpretability.</p><br>
                    </section>
                    
                    <section>
                        <h3>5.10 Neural Net learning and genetic learning:</h3>
                        <br>
                        <p>Learning using neural networks and genetic algorithms are two powerful techniques in artificial intelligence and machine learning.</p><br>
                        <p><strong>Neural networks</strong>, inspired by the structure of the human brain, consist of interconnected nodes arranged in layers. They process input data through weighted connections, apply activation functions, and produce output. Neural networks offer advantages like parallel processing, the ability to work with incomplete knowledge, and fault tolerance. However, determining the proper network structure and understanding network behavior can be challenging.</p><br>
                        <p><strong>Genetic algorithms</strong>, based on principles of natural evolution, are optimization algorithms that mimic the process of natural selection. They operate by maintaining a population of solutions represented as chromosomes and evolve these solutions through selection, crossover, and mutation. Genetic algorithms are effective for optimization problems, but defining a suitable representation and fitness function is crucial.</p><br>
                        <p>The relationship between neural networks and genetic algorithms lies in their application to learning and optimization tasks. Neural networks can be evolved using genetic algorithms to improve their performance and adaptability. Genetic algorithms can be employed to optimize neural network architectures, weights, and learning rules.</p><br>
                        <p>Both techniques find applications across various domains. Neural networks are used for tasks like pattern recognition, classification, and prediction, while genetic algorithms are applied to optimization problems in robotics, financial planning, and more.</p><br>
                        <p>In summary, neural networks and genetic algorithms are complementary approaches in artificial intelligence and machine learning, offering powerful tools for solving complex problems and optimizing systems. Understanding their principles, advantages, and limitations is essential for effectively applying them in engineering and other fields.</p><br>
                    </section>

                    <section>
                        <h3>5.11 Expert System:</h3>
                        <br>
                        <p>Expert systems, a subset of artificial intelligence, replicate human decision-making processes. Originating in 1970, they tackle complex issues in specific domains like medicine and science. Notable examples include DENDRAL and MYCIN, aiding in chemical analysis and bacterial infection diagnosis, respectively.</p><br>
                        <p>Characterized by high performance, user-friendliness, and reliability, expert systems comprise three main components: the user interface, inference engine, and knowledge base. They excel in tasks like advising, decision-making, and problem-solving.</p><br>
                        <p>While offering reproducibility and speed, expert systems face limitations such as dependency on accurate knowledge and high maintenance costs. Nevertheless, they find applications in diverse fields, from manufacturing to finance, medical diagnosis, and planning tasks efficiently.</p><br>
                        <p>In essence, expert systems leverage AI to mimic human expertise, providing invaluable decision-making support across various domains. Understanding their components and applications is crucial for effective problem-solving in complex scenarios.</p><br>
                    </section>
                    
                    <section>
                        <h3>5.12 Expert system shells and knowledge acquisition:</h3>
                        <br>
                        <p>Expert system shells serve as software development environments for building applications by configuring and instantiating basic components. These components include the knowledge base, reasoning engine, explanation subsystem, and user interface.</p><br>
                        <p>The knowledge base stores both factual and heuristic knowledge, utilizing various representation schemes such as frames or logical statements. Meanwhile, the reasoning engine manipulates symbolic information to derive solutions, employing mechanisms ranging from simple IF-THEN rules to case-based reasoning.</p><br>
                        <p>Knowledge acquisition poses a significant challenge in building expert systems, as collecting the necessary knowledge from experts can be a bottleneck. However, tools and subsystems aid in this process by assisting experts in building knowledge bases.</p><br>
                        <p>The explanation subsystem justifies the system's actions, providing insights into how solutions were reached and the need for additional data. Finally, the user interface facilitates communication with users, enhancing the perceived utility of the expert system.</p><br>
                    </section>
                    
                    <section>
                        <h3>5.13 Representing and using domain knowledge:</h3>
                        <br>
                        <p>Expert systems in AI replicate human decision-making within specific domains by encoding and organizing domain knowledge. They consist of a Knowledge Base (KB), an Inference Engine, and a User Interface to interact with users.</p><br>
                        <p>Domain knowledge is represented using rule-based systems like production rules and fuzzy logic, as well as knowledge representation techniques like semantic networks, frames, and ontologies. Case-Based Reasoning (CBR) stores past experiences to solve new problems, while heuristic knowledge captures expert rules of thumb.</p><br>
                        <p>These systems find application in various fields, such as medical diagnosis, financial advice, troubleshooting, and natural language processing. Their advantages include consistency, availability, and facilitating training and knowledge sharing. However, challenges like knowledge acquisition and limitations in common sense reasoning exist.</p><br>
                        <p>Overall, expert systems are vital in AI for encapsulating domain-specific knowledge and offering intelligent solutions. They serve as invaluable decision support tools across diverse domains, contributing significantly to problem-solving and decision-making processes.</p><br>
                    </section>
                    
                </div>

            </div>

            <!-- New section for notes -->
            <div class="notes-section">
                <h2>Save Your Useful Notes</h2>
                <div class="input-container">
                    <textarea id="notes" rows="10" cols="50" placeholder="Enter your notes here..."></textarea>
                </div>
                <br>
                <button id="save-btn">Save</button>
            </div>
            <a href="main.html" class="home-button">&#8962;</a>
        </div>
x
    </main>

    <footer>

        <div class="footer-wrapper" >
            <div class="footer-link-heading">Contact Us
            <div class="gfg-info">


                <a href="https://mail.google.com/mail/?view=cm&to=majorproject2024cse@gmail.com&su=&body=&bcc=" class="gfg-info-elems"><span class="material-symbols-outlined" style="color: var(--gfg-green); padding: 5px;">mail</span>majorproject2024cse@gmail.com</a>
                
            </div>
            
            <a href="about.html"><div class="footer-link-heading">About Us</div></a>
        </div>


            <div class="footer-strip">

            </div>

        </div>

    </footer>

</body>

</html>
